<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Gitlab | A Rambling On</title>
    <link>/tag/gitlab/</link>
      <atom:link href="/tag/gitlab/index.xml" rel="self" type="application/rss+xml" />
    <description>Gitlab</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Thu, 15 Jun 2023 02:14:14 -0700</lastBuildDate>
    <image>
      <url>/img/Bayes.jpg</url>
      <title>Gitlab</title>
      <link>/tag/gitlab/</link>
    </image>
    
    <item>
      <title>CI/CD Part 4: Container Registries</title>
      <link>/post/cicd-4-cr/</link>
      <pubDate>Thu, 15 Jun 2023 02:14:14 -0700</pubDate>
      <guid>/post/cicd-4-cr/</guid>
      <description>&lt;p&gt;This is the last post in a mini-series on 
&lt;a href=&#34;/post/cicd-1-config/&#34;&gt;designing Gitlab CI/CD pipelines&lt;/a&gt;.  We&amp;rsquo;ve discussed the basic anatomy of a &lt;code&gt;.gitlab-ci.yml&lt;/code&gt; file, how to set up authentication tokens and files for building and pushing packages to a registry, and designing a Dockerfile for building images from a package in the context of a CI/CD pipeline.  In this post, I&amp;rsquo;m going to show how to push your package to a remote AWS Elastic Container Registry (ECR).&lt;/p&gt;
&lt;p&gt;The structure of this CI/CD job will be analogous to the CI/CD job defined at the end of our first 
&lt;a href=&#34;/post/cicd-1-config/&#34;&gt;post&lt;/a&gt;, where we pushed an image to the Gitlab Container Registry.&lt;/p&gt;
&lt;h4 id=&#34;setting-up-aws-variables&#34;&gt;Setting up AWS variables&lt;/h4&gt;
&lt;p&gt;To build images, tag them, and push them to the remote AWS ECR, I used the definition of a CI/CD job below.  In addition to pre-defined variables that are set internally by Gitlab, we can also manually pre-define variables.  In this case, I&amp;rsquo;ve set a few that allow me to interact with AWS via the command line:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;AWS_DEFAULT_REGION&lt;/code&gt;: self-explanatory&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ECR_REPO_LAMBDA&lt;/code&gt;: &lt;code&gt;${AWS_ACCOUNT_ID}&lt;/code&gt;.dkr.ecr.&lt;code&gt;${AWS_DEFAULT_REGION}&lt;/code&gt;.amazonaws.com/&lt;code&gt;${YOUR_ECR_REPO_NAME}&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;AWS_ACCOUNT_ID&lt;/code&gt;: AWS account ID&lt;/li&gt;
&lt;li&gt;&lt;code&gt;AWS_ACCESS_KEY&lt;/code&gt;: this is the information contained in the downloaded *.pem file&lt;/li&gt;
&lt;li&gt;&lt;code&gt;AWS_SECRET_ACCESS_KEY&lt;/code&gt;: this is the information contained in the downloaded *.pem file&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To set variables that are accessible by CI/CD jobs, go to your &lt;strong&gt;Project/Group &amp;gt; Settings &amp;gt; CI/CD &amp;gt; Variables &amp;gt; Expand&lt;/strong&gt; and define the variables of interest:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./CICD.VariableTab.png&#34; alt=&#34;&#34;&gt;
&lt;img src=&#34;./CICD.Variables.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;If you define these variables at the Gitlab Group level, they will be propagated down to the project level, so long as the Project falls under the Group scope.&lt;/p&gt;
&lt;h4 id=&#34;pushing-to-aws-ecr-via-cicd-job&#34;&gt;Pushing to AWS ECR via CI/CD job&lt;/h4&gt;
&lt;p&gt;Below, we define the actual CI/CD job.   There were two aspects here that I needed to solve.  First, I needed access to a Docker-in-Docker build image e.g. an image that had Docker installed.  And second, this image also needed to have the AWS CLI tool installed.  To that end, I used the &lt;code&gt;bentolor/docker-dind-awscli&lt;/code&gt; 
&lt;a href=&#34;https://github.com/bentolor/docker-dind-awscli&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;image&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;build-image-ecr:
  stage: deploy 
  image: bentolor/docker-dind-awscli
  services:
    - docker:dind
  variables:
    # convenience variable indicating name of the image with respect to the ECR repo and unique tag ID
    IMAGE_TAG: $ECR_REPO_LAMBDA:$CI_COMMIT_SHORT_SHA

  before_script:
    - docker info
    # authenticate docker with your AWS ECR account
    - aws ecr get-login-password --region $AWS_DEFAULT_REGION | docker login --username AWS --password-stdin $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com
  # will push Docker image to AWS ECR
  script:
    # build the docker imagae
    - docker build --compress -t ${IMAGE_TAG} .
    # tag the image with a unique name
    - docker tag ${IMAGE_TAG} $ECR_REPO_LAMBDA:latest
    # push the image to the ECR
    - docker push ${IMAGE_TAG}

  # here, we only build and push the image if this is a merge event into the &amp;quot;main&amp;quot; branch
  rules:
    - if: $CI_PIPELINE_SOURCE == &#39;merge_request_event&#39; &amp;amp;&amp;amp; $CI_MERGE_REQUEST_TARGET_BRANCH_NAME == &amp;quot;main&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And voila!  You have now pushed your built image to a remote container registry!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>CI/CD Part 3: Building containers with Docker</title>
      <link>/post/cicd-3-docker/</link>
      <pubDate>Tue, 30 May 2023 02:14:14 -0700</pubDate>
      <guid>/post/cicd-3-docker/</guid>
      <description>&lt;p&gt;This is the third post in a mini-series on 
&lt;a href=&#34;/post/cicd-1-config/&#34;&gt;designing Gitlab CI/CD pipelines&lt;/a&gt;.  In the last 
&lt;a href=&#34;/post/cicd-2-packages/&#34;&gt;post&lt;/a&gt;, we discussed setting up your &lt;code&gt;.pypirc&lt;/code&gt; and &lt;code&gt;.netrc&lt;/code&gt; files in the context of a Gitlab CI/CD pipeline to enable building and pushing packages to a package registry, as well as for installing code from a private registry.  In this post, we&amp;rsquo;ll discuss putting together a Dockerfile for building containers in the context of a Gitlab CI/CD pipeline.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m using what&amp;rsquo;s called a &amp;ldquo;multi-stage&amp;rdquo; build.  This is exactly what it sounds like &amp;ndash; it breaks the process of building a Docker image into multiple stages.  In doing so, we often have the benefit of a final image that is smaller than a single-stage build, because we only include the artifacts needed to run our containerized application.&lt;/p&gt;
&lt;p&gt;Similarly, we can leverage multi-stage Docker builds to minimize duplicated code in Dockerfiles.  For example, let&amp;rsquo;s say we have a scenario where we want to build an image for a &lt;code&gt;Production&lt;/code&gt; environment as well as a &lt;code&gt;Test&lt;/code&gt; environment.  The &lt;code&gt;Test&lt;/code&gt; environment might include some additional dependencies, scripts, exports, etc. that the Production environment doesn&amp;rsquo;t.  Instead of creating two Dockerfiles, one for each environment, we can define a single-stage that encompasses the overlapping parts of both the &lt;code&gt;Production&lt;/code&gt; and &lt;code&gt;Test&lt;/code&gt; images, and then define the extra stuff in a separate stage to build the &lt;code&gt;Test&lt;/code&gt; image.&lt;/p&gt;
&lt;p&gt;In the example below, we have a three-stage Docker build, with stage names:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;base&lt;/code&gt;: sets up some basic environment variables&lt;/li&gt;
&lt;li&gt;&lt;code&gt;python-deps&lt;/code&gt;: installs your package and creates a virtual environment&lt;/li&gt;
&lt;li&gt;&lt;code&gt;runtime&lt;/code&gt;: the actual application you want to run, with only the necessary files for running it&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;create-a-base-image&#34;&gt;Create a base image&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;# set base image
# bigger base images yield slower image load times, and have more security vulnerabilities
FROM python:3.9-slim as base

# install virtual environment in ${project_dir}/.venv
ENV PIPENV_VENV_IN_PROJECT 1
# dont write .pyc files
ENV PYTHONDONTWRITEBYTECODE 1
# get some more information about faults when building images
ENV PYTHONFAULTHANDLER 1
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;install-package-dependencies&#34;&gt;Install package dependencies&lt;/h4&gt;
&lt;p&gt;If you were building your Docker image locally, you&amp;rsquo;d have access to any authentication tokens or SSH keys necessary to pull from remote or private repositories.  However, Docker is naive to these variables &amp;ndash; we have to explicitly provide them at build time. Within the Dockerfile, we define three environment variables using the &lt;code&gt;ARG&lt;/code&gt; keyword:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;CI_DEPLOY_USER&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;CI_DEPLOY_PASSWORD&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;CI_JOB_TOKEN&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If you think that these variables look familiar, you&amp;rsquo;re right.  They&amp;rsquo;re the same pre-defined variables that exist in the context of a Gitlab CI/CD pipeline that act as authentication tokens for a &lt;code&gt;.pypric&lt;/code&gt; file and &lt;code&gt;.netrc&lt;/code&gt; &amp;ndash; they&amp;rsquo;re utilized by the &lt;code&gt;setup_tokens.sh&lt;/code&gt; script to setup the &lt;code&gt;.pypirc&lt;/code&gt; and &lt;code&gt;.netrc&lt;/code&gt; files &lt;em&gt;within&lt;/em&gt; the Docker image.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;# image for installing dependencies
# we only need .venv and app `runtime` image, not all other bloat
FROM base AS python-deps

####################################
# ----------------------------------
ARG CI_DEPLOY_USER
ARG CI_DEPLOY_PASSWORD
ARG CI_JOB_TOKEN
# ----------------------------------
####################################
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These variable are available outside of the Docker image, but not within the image itself, so we need to &amp;ldquo;show&amp;rdquo; them to Docker at build time via the &lt;code&gt;--build-arg&lt;/code&gt; flag:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker build --build-arg CI_DEPLOY_USER=$CI_DEPLOY_URDER \
             --build-arg CI_DEPLOY_PASSWORD=$CI_DEPLOY_PASSWORD \
             --build-arg CI_JOB_TOKEN=$CI_JOB_TOKEN \
             ...
             ...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now they are contained within the Docker image and can be provided to the &lt;code&gt;setup_tokens.sh&lt;/code&gt; script, which then allows us to pull packages down from our remote package registry.  We also no longer need the SSH keys, since we&amp;rsquo;re authenticating through Gitlab itself.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;# install pipenv in `python-deps` image
RUN python3 -m pip install pipenv
RUN apt-get update \
    &amp;amp;&amp;amp; apt-get install --yes --no-install-recommends gcc g++ libffi-dev

# Dependency installation looks a little different for local packages
WORKDIR /home/app


# copy files to `python-deps` image
COPY setup.py setup_tokens.sh Pipfile Pipfile.lock ./
# copy over application-specific code that you want to install
# this is unique to my specific project -- use your own directories here
COPY templateci/ templateci/

# run setup_tokens script to setup .pypirc and .netrc within image
RUN chmod +x ./setup_tokens.sh &amp;amp;&amp;amp; ./setup_tokens.sh

# authentication tokens are now available to pipenv
RUN python3 -m pipenv install --deploy --dev

# get rid of unnecessary libraries after install
RUN apt-get autoremove --yes gcc g++ libffi-dev \
    &amp;amp;&amp;amp; rm -rf /var/lib/apt/lists/*
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;create-your-final-runtime-image&#34;&gt;Create your final runtime image&lt;/h4&gt;
&lt;p&gt;Above, we created the virtual environment that allows our application to run.  As such, we no longer need the raw source code or any other random files that were contained in the original project directory that might have been needed to build the virtual environment.  Now we create a stage called &lt;code&gt;runtime&lt;/code&gt; in which we copy over the generated virtual environment from the previous stage&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;# image for running the application
FROM base AS runtime

# Copy virtual environment from `python-deps` image to `runtime` image
COPY --from=python-deps /home/app/.venv /.venv
# add virtual environment to PATH
ENV PATH=&amp;quot;/.venv/bin:$PATH&amp;quot;

# Create new user -- app will run as new user
RUN useradd --create-home -u 1099 user
WORKDIR /home/user/app
USER user

COPY . .

CMD [&amp;quot;python3&amp;quot;, &amp;quot;-m&amp;quot;, &amp;quot;pytest&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is the actual image that get&amp;rsquo;s run when we call&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run ${IMAGE_NAME}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>CI/CD Part 2: Building and pushing packages</title>
      <link>/post/cicd-2-packages/</link>
      <pubDate>Fri, 12 May 2023 02:14:14 -0700</pubDate>
      <guid>/post/cicd-2-packages/</guid>
      <description>&lt;p&gt;This is the second post in a mini-series on 
&lt;a href=&#34;/post/cicd-1-config/&#34;&gt;designing Gitlab CI/CD pipelines&lt;/a&gt;.  In order to build packages and push them to a remote package registry, we use the &lt;code&gt;build&lt;/code&gt; and &lt;code&gt;twine&lt;/code&gt; packages.  &lt;code&gt;build&lt;/code&gt; generates a package, and &lt;code&gt;twine&lt;/code&gt; pushes this package to a registry (or &amp;ldquo;index&amp;rdquo;).  &lt;code&gt;twine&lt;/code&gt; requires access to authentication usernames, passwords, and a registry URL in order to do so.  &lt;code&gt;twine&lt;/code&gt; can access these tokens from a &lt;code&gt;.pypirc&lt;/code&gt; file &amp;ndash; the tokens are generated by the registry, and ensure that the submitting user has permissions to perform a certain action.&lt;/p&gt;
&lt;p&gt;Other processes, such as pulling or pushing code from a remote repository, often require additional usernames and passwords.  In order to alleviate the need to consistently provide these variables at request time, we can save them in a &lt;code&gt;.netrc&lt;/code&gt; file.&lt;/p&gt;
&lt;p&gt;These are straightforward to set up locally.  But we also need to set these up to ensure a properly functional CI/CD workflow.  I&amp;rsquo;ve put together a basic script, called &lt;code&gt;setup_tokens.sh&lt;/code&gt; that does just that:&lt;/p&gt;
&lt;h4 id=&#34;setup_tokenssh&#34;&gt;setup_tokens.sh&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/bash

# generate .pypirc file
echo &amp;quot;[distutils]
index-servers =
    personal

[personal]
repository = https://gitlab.com/api/v4/projects/$PACKAGE_REGISTRY_ID/packages/pypi
username = $CI_DEPLOY_USER
password = $CI_DEPLOY_PASSWORD&amp;quot; &amp;gt; ~/.pypirc

# generate .netrc file
echo &amp;quot;machine gitlab.com
login gitlab-ci-token
password $CI_JOB_TOKEN&amp;quot; &amp;gt; ~/.netrc
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;.pypirc&lt;/code&gt; refers to your Project Registry via a previously generated authentication token and password, and allows your to build and upload Python packages to that registry.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;.netrc&lt;/code&gt; file enables you to pull private packages from that same registry.  In the context of our work, we&amp;rsquo;ll want to build and push packages to the registry first so that they are available for pulling.  For example, in the &lt;code&gt;Pipfile&lt;/code&gt; for this template project, we have the following:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;[[source]]
url = &amp;quot;https://pypi.org/simple&amp;quot;
verify_ssl = true
name = &amp;quot;pypi&amp;quot;

[[source]]
url = &amp;quot;https://${CI_DEPLOY_USER}:${CI_DEPLOY_PASSWORD}@gitlab.com/api/v4/projects/${$PACKAGE_REGISTRY_ID}/packages/pypi/simple&amp;quot;
verify_ssl = true
name = &amp;quot;personal&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see the same user authentication happening, along with the reference to the Package Registry ID variable.  For local installation of your package, and in order to make sure that your &lt;code&gt;Pipfile&lt;/code&gt; and &lt;code&gt;Pipfile.lock&lt;/code&gt; are in sync, you&amp;rsquo;ll need to define the following local environment variables:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;CI_DEPLOY_USER&lt;/code&gt;: generated user token&lt;/li&gt;
&lt;li&gt;&lt;code&gt;CI_DEPLOY_PASSWORD&lt;/code&gt;: generated token password&lt;/li&gt;
&lt;li&gt;&lt;code&gt;PACKAGE_REGISTRY_ID&lt;/code&gt;: the ID of the repository that you created that will store your packages&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Building a package locally is straightforward, but doing so within a Gitlab CI/CD pipeline is a little more complicated.  But, we can imagine adding this type of task to a CI/CD pipeline, and conditioning it on a merge request (or something of that kind).&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ve called this job &lt;code&gt;build-package&lt;/code&gt; and it belongs to a stage also called &lt;code&gt;build-package&lt;/code&gt;.  We first set up the &lt;code&gt;.pypirc&lt;/code&gt; and &lt;code&gt;.netrc&lt;/code&gt; files in image running the job, and then install the &lt;code&gt;build&lt;/code&gt; and &lt;code&gt;twine&lt;/code&gt; libraries in the &lt;code&gt;before_script&lt;/code&gt; attribute.  Then, using the &lt;code&gt;script&lt;/code&gt; attribute, we build our package, and push it to our package registry (we&amp;rsquo;ve defined the registry in our &lt;code&gt;.pypirc&lt;/code&gt; file &amp;ndash; here, it&amp;rsquo;s referred to as the &amp;ldquo;personal&amp;rdquo; registry.)&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;image: python:3.9-slim
variables:
  PACKAGE_REGISTRY_NAME: &amp;quot;personal&amp;quot;

stages:
  - build-package

#### BUILDING PACKAGE AND PUSHING TO GITLAB PACKAGE REGISTRY
build-package:
  stage: build-package
  before_script:
    - chmod +x ./setup_tokens.sh; ./setup_tokens.sh
    - apt-get update
    - apt-get install --yes --no-install-recommends gcc g++ libffi-dev
    - python3 -m pip install build twine
  script:
    - python3 -m build
    - python3 -m twine upload --repository ${PACKAGE_REGISTRY_NAME} dist/* --verbose
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>CI/CD Part 1: Gitlab Pipelines</title>
      <link>/post/cicd-1-config/</link>
      <pubDate>Tue, 02 May 2023 02:14:14 -0700</pubDate>
      <guid>/post/cicd-1-config/</guid>
      <description>&lt;p&gt;I recently developed a template workflow to help our team adopt a CI/CD-based development strategy.  Many of our web applications and tools were based on simple repository structures.  With growing datasets and ever-increasing use by outside teams, we found ourselves needing to add new features more frequently to many of these tools and believed that continuous integration and deployment could help us not just develop more quickly, but also more intelligently.  Since we use Gitlab to store our code, we decided to use the Gitlab CI/CD tools.&lt;/p&gt;
&lt;p&gt;Documentation on much of this process was scattered and/or sparse, so I decided to put what I learned and implemented into a more coherent set of notes.  The current post relates to a basic setup of the &lt;code&gt;.gitlab-ci.yml&lt;/code&gt; file and using Gitlab CI/CD.  The next few posts are about what I learned in the process of setting this up, where I&amp;rsquo;ll discuss:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;/post/cicd-2-packages/&#34;&gt;Setting&lt;/a&gt; up authentication for pushing packages to a package registry and for pulling down private repositories&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;/post/cicd-3-docker/&#34;&gt;Designing&lt;/a&gt; Dockerfiles for building images using CI/CD&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;/post/cicd-4-cr/&#34;&gt;Pushing&lt;/a&gt; images to a container registry&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;setup&#34;&gt;Setup&lt;/h2&gt;
&lt;p&gt;I did all of my testing using my personal Gitlab account.  To separate things out, I created a new Project called &amp;ldquo;Package Registry”, as well as a test repository that was used for building a local Python project called &amp;ldquo;TemplateCI&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;The &amp;ldquo;Package Registry&amp;rdquo; Project serves as just that &amp;ndash; an all-inclusive location for any software packages your CI/CD pipelines build.  You can find the built packages by clicking &lt;strong&gt;${Project Name} &amp;gt; Deploy &amp;gt; Package Registry&lt;/strong&gt;.  Every &amp;ldquo;Project&amp;rdquo; in Gitlab has the ability to store packages in its own registry, but I felt it cleaner to store everything in one repo.  Similarly, the actual code that I&amp;rsquo;ll be packaging will be stored in the &amp;ldquo;TemplateCI&amp;rdquo; repo.&lt;/p&gt;
&lt;h2 id=&#34;basic-jobs&#34;&gt;Basic jobs&lt;/h2&gt;
&lt;p&gt;The basis of a Gitlab CI/CD pipeline is the &lt;code&gt;.gitlab-ci.yml&lt;/code&gt; file, which is composed of a set of explicitly-defined and temporally-ordered “stages”.  A stage is composed of a set of “jobs”.  Jobs are the workhorses of the CI/CD pipeline, and define explicit tasks that a CI/CD pipeline runs.  By default, all jobs from one stage run in parallel, unless specified otherwise (using the &lt;code&gt;needs&lt;/code&gt; keyword as an attribute of a job induces a temporal directed acyclic graph – jobs can be made “dependent” on the successful completion of other jobs within a stage).  In this example, I’ve defined three stages:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;run-unit-tests&lt;/li&gt;
&lt;li&gt;build-package&lt;/li&gt;
&lt;li&gt;build-image&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Any job associated with the &lt;code&gt;run-unit-tests&lt;/code&gt; stage will run to completion (or failure) PRIOR TO ANY job in the stages &lt;code&gt;build-package&lt;/code&gt; and &lt;code&gt;build-image&lt;/code&gt; starting.  If all jobs in the &lt;code&gt;run-unit-tests&lt;/code&gt; stage complete successfully, then the next stage (&lt;code&gt;build-package&lt;/code&gt;) will begin.  We define individual jobs, and give them a stage attribute.  Stages define the rough ordering of jobs.  Each job runs in the context of an “image” or environment.  We can set a global &lt;code&gt;image&lt;/code&gt; and define stages as&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;# global CI/CD image
image: python:3.9-slim

# stages of this example pipeline
stages:
  - run-unit-tests
  - build-package
  - build-image

 variables:
    LC_ALL: C.UTF-8
    LANG: C.UTF-8
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or define the image as an attribute of a job.  Gitlab CI/CD by default uses Docker images in which to run jobs.  Setting the image is analogous to using the &lt;code&gt;FROM&lt;/code&gt; command in a Dockerfile.  We&amp;rsquo;ve also set some global variables, here the &lt;code&gt;LC_ALL&lt;/code&gt; and &lt;code&gt;LANG&lt;/code&gt; variables.&lt;/p&gt;
&lt;p&gt;To “run” Gitlab pipelines for the purpose of CI/CD, we use “runners”, which are build instances installed on a server.  Gitlab offers “shared” runners (use of these is free if you use 
&lt;a href=&#34;https://www.gitlab.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;www.gitlab.com&lt;/a&gt;, but you need to register a credit card to prevent abuse of Gitlab resources).  You can also register your own device(s) to act as a Gitlab runner.&lt;/p&gt;
&lt;p&gt;Below are examples of two jobs in the &lt;code&gt;run-unit-tests&lt;/code&gt; stage.  These two jobs are effectively the same code, apart from the unique unit tests that they run.  However, we&amp;rsquo;ve made the job &lt;code&gt;unit-tests-2&lt;/code&gt; dependent on the output of the job &lt;code&gt;unit-tests-1&lt;/code&gt; (see the &lt;code&gt;needs&lt;/code&gt; keyword of &lt;code&gt;unit-tests-2&lt;/code&gt;) .  Both jobs use the global &lt;code&gt;python:3.9-slim&lt;/code&gt; image.  We can run some “setup”  stuff (&lt;code&gt;before_script&lt;/code&gt;), run an actual script (&lt;code&gt;script&lt;/code&gt;), and run clean up (&lt;code&gt;after_script&lt;/code&gt;, not shown) &amp;ndash; these delineations (before, during, after) are for organizational purposes, and not due to any explicit functional differences in the delineations.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;### Ignore the script called &amp;quot;setup_tokens.sh&amp;quot; for now -- we&#39;ll discuss this in another post. ###


# example job #1
unit-tests-1:
  stage: run-unit-tests
  before_script:
    - chmod +x ./setup_tokens.sh; ./setup_tokens.sh
    - python3 -m pip install pipenv
    - apt-get update
    - apt-get install --yes --no-install-recommends gcc g++ libffi-dev
    - python3 -m pipenv install --deploy --dev
  # run first set of unit tests
  script:
    - python3 -m pipenv run pytest -k &#39;test_examples1.py&#39;
 

# example job #2
unit-tests-2:
  stage: run-unit-tests
  before_script:
    - chmod +x ./setup_tokens.sh; ./setup_tokens.sh
    - python3 -m pip install pipenv
    - apt-get update
    - apt-get install --yes --no-install-recommends gcc g++ libffi-dev
    - python3 -m pipenv install --deploy --dev
  # run second set of unit tests
  script:
    - python3 -m pipenv run pytest -k &#39;test_examples2.py&#39;
  # wait for job 1 to finish
  needs: [unit-tests-1]
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;conditional-pipeline-jobs&#34;&gt;Conditional pipeline jobs&lt;/h2&gt;
&lt;p&gt;The above jobs are relatively simple and will run every time you push a repository to Gitlab.  However, sometimes, we might only want to run a job if certain conditions are met.  For example, we might only want to build a package from the &lt;code&gt;main&lt;/code&gt; branch, or only after a merge request is made.  To this end, we can add “rules” to a job that restrict when it is actually run.&lt;/p&gt;
&lt;p&gt;Below is a more complicated job example.  The overarching goal of this job is to build a Docker image from a local Python project and push the image to the Gitlab Container Registry.  There’s a lot going on here, so I’ll break it up into pieces, but here is the whole job:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;# Conditional job
# Building a docker image and pushing this container to a container registry
# Link to main image: https://github.com/bentolor/docker-dind-awscli

# Conditions:
# --- merge request events
# --- target branch of merge request is &amp;quot;main&amp;quot;

# job name
build-image-glcr:
  
  # stage of pipeline
  stage: build-image
  # image that job is based on
  image: docker:20.10.16
  # sub-services of job
  services:
    - docker:20.10.16-dind
  # variables available to the job
  variables:
    DOCKER_TLS_CERTDIR: &amp;quot;/certs&amp;quot;
    IMAGE_TAG: $CI_REGISTRY_IMAGE:$CI_COMMIT_REF_SLUG
    
  # some setup scripts -- here, just making sure docker is available
  before_script:
    - docker info

  # meat of the job -- authentication, building, run, push
  script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
    - docker build 
      --build-arg CI_DEPLOY_USER=$CI_DEPLOY_USER 
      --build-arg CI_DEPLOY_PASSWORD=$CI_DEPLOY_PASSWORD 
      --build-arg CI_JOB_TOKEN=$CI_JOB_TOKEN
      -t $IMAGE_TAG .
    - docker run $IMAGE_TAG
    - docker push $IMAGE_TAG

  # job conditions
  rules:
    - if: $CI_PIPELINE_SOURCE == &#39;merge_request_event&#39; &amp;amp;&amp;amp; $CI_MERGE_REQUEST_TARGET_BRANCH_NAME == &amp;quot;main&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This job is associated with a new stage called &lt;code&gt;build-image&lt;/code&gt; that will run as the last stage of this example CI/CD pipeline.  Without going into the specifics of the 
&lt;a href=&#34;/post/cicd-3-docker/&#34;&gt;Dockerfile&lt;/a&gt; just yet, this stage builds and pushes a Docker image to a remote repository.  We defined the job image as &lt;code&gt;docker:20.10.16&lt;/code&gt; and an additional “service” attribute as &lt;code&gt;docker:20.10.16-dind&lt;/code&gt; where “dind” means “Docker-in-Docker”.  The Docker-in-Docker feature allows an image to run Docker itself (pretty meta, huh).  The idea here is to instantiate a job from a specific Docker container (“image”) which itself has Docker installed (“dind”), which will allow the docker:20.10.16 image to build &lt;em&gt;another&lt;/em&gt; Docker container.  We’ve also defined some variables:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;DOCKER_TLS_CERTDIR&lt;/code&gt;: needed to allow the larger scale image to communicate with a service (honestly, I don’t quite understand this and documentation on CI/CD &amp;ldquo;services&amp;rdquo; is sparse)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;IMAGE_TAG&lt;/code&gt;: refers to the container destination and the image “name” &amp;ndash; this just makes our lives easier by turning into a variable what would otherwise be a really long string&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;#### Build Docker image and push to Gitlab Container Registry
build-image-glcr:
  stage: build-image
  image: docker:20.10.16
  services:
    - docker:20.10.16-dind
  variables:
    DOCKER_TLS_CERTDIR: &amp;quot;/certs&amp;quot;
    IMAGE_TAG: $CI_REGISTRY_IMAGE:$CI_COMMIT_REF_SLUG
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next up, we have all the script stuff.  You’ll probably recognize most of the &lt;code&gt;docker ${command}&lt;/code&gt; commands.  We first “authenticate” the current job with the Gitlab container registry (apparently there are a variety of ways to “authenticate” with Docker using one set of variables or another – the way below is the way I was able to get working, but there are 
&lt;a href=&#34;https://stackoverflow.com/questions/61251622/how-to-authenticate-to-gitlabs-container-registry-before-building-a-docker-imag&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;other solutions&lt;/a&gt;).  We then build the Docker image, run the image, and push the image to the container registry.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;script:
  - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
  - docker build 
    --build-arg CI_DEPLOY_USER=$CI_DEPLOY_USER 
    --build-arg CI_DEPLOY_PASSWORD=$CI_DEPLOY_PASSWORD 
    --build-arg CI_JOB_TOKEN=$CI_JOB_TOKEN
    -t $IMAGE_TAG .
  - docker run $IMAGE_TAG
  - docker push $IMAGE_TAG
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You’ll notice a bunch of variables that I didn&amp;rsquo;t explicitly define anywhere:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;CI_REGISTRY_USER&lt;/code&gt;: username for project (I think we can also use &lt;code&gt;CI_DEPLOY_USER&lt;/code&gt;, though it looks like there might be some things to figure out with branch / variable protections / non-protections)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;CI_REGISTRY_PASSWORD&lt;/code&gt;: defaults to &lt;code&gt;CI_JOB_TOKEN&lt;/code&gt; value (this value is ephemeral e.g. valid only for one job at a time I think?  I think we can also use the &lt;code&gt;CI_DEPLOY_PASSWORD&lt;/code&gt; for a longer-lived alternative, though it looks like there might be some things to figure out with branch / variable protections / non-protections)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;CI_REGISTRY&lt;/code&gt;: defaults to &lt;code&gt;https://gitlab.com/${group}/${project-name}/container_registry&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;CI_DEPLOY_USER&lt;/code&gt;: generated user token&lt;/li&gt;
&lt;li&gt;&lt;code&gt;CI_DEPLOY_PASSWORD&lt;/code&gt;: generated token password&lt;/li&gt;
&lt;li&gt;&lt;code&gt;CI_JOB_TOKEN&lt;/code&gt;: see documentation 
&lt;a href=&#34;https://docs.gitlab.com/ee/ci/jobs/ci_job_token.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These are all 
&lt;a href=&#34;https://docs.gitlab.com/ee/ci/variables/predefined_variables.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;“predefined” variables&lt;/a&gt;, meaning they already exist in the Gitlab CI/CD context as part of having a 
&lt;a href=&#34;https://www.gitlab.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;www.gitlab.com&lt;/a&gt; account, without you explicitly defining them.  However, I did run into some issues using &lt;code&gt;CI_DEPLOY_USER&lt;/code&gt; and &lt;code&gt;CI_DEPLOY_PASSWORD&lt;/code&gt;.  In addition to having predefined variables provided by Gitlab CI/CD, we can also 
&lt;a href=&#34;./docs/SettingEnvVariables.md&#34;&gt;&lt;em&gt;manually&lt;/em&gt; predefine variables&lt;/a&gt; for a whole Gitlab Project or for a whole Group.  Go the page for your &lt;strong&gt;Project/Group &amp;gt; Settings &amp;gt; CI/CD &amp;gt; Variables &amp;gt; Expand&lt;/strong&gt;.  For example, I defined the &lt;code&gt;CI_DEPLOY_USER&lt;/code&gt; and &lt;code&gt;CI_DEPLOY_PASSWORD&lt;/code&gt; variables for my Group.  These variables are the Group-level authentication tokens and are now made accessible to all Gitlab CI/CD jobs running under this Group.  Additionally, although not shown here (because it&amp;rsquo;s used within the &lt;code&gt;setup_tokens.sh&lt;/code&gt; script), we&amp;rsquo;ve also defined an environment variable called &lt;code&gt;PACKAGE_REGISTRY_ID&lt;/code&gt; that tells the CI/CD pipeline where to build and push packages.&lt;/p&gt;
&lt;p&gt;And finally, what we’ve been waiting for, conditional pipeline jobs:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;rules:
  - if: $CI_PIPELINE_SOURCE == &#39;merge_request_event&#39; &amp;amp;&amp;amp; $CI_MERGE_REQUEST_TARGET_BRANCH_NAME == &amp;quot;main&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As part of this job, I&amp;rsquo;ve defined a rule that indicates that this job should &lt;strong&gt;only&lt;/strong&gt; be run 1) upon a merge request event (i.e. if you click “Create Merge Request” in the console), and 2) if the name of the target branch of that merge request event is &lt;code&gt;main&lt;/code&gt;.  For example, if I create a new branch called &lt;code&gt;dev&lt;/code&gt; off of &lt;code&gt;main&lt;/code&gt; and create a merge request in the Gitlab console, this job will run.  However, it’s important to note that, if you push a commit to the &lt;code&gt;dev&lt;/code&gt; branch &lt;em&gt;after&lt;/em&gt; creating the merge request, this job will &lt;em&gt;still&lt;/em&gt; run, even if you havn’t created a &lt;em&gt;new&lt;/em&gt; merge request e.g. &lt;code&gt;CI_PIPELINE_SOURCE&lt;/code&gt; == &amp;ldquo;merge_request_event&amp;rdquo; will always default to &lt;code&gt;TRUE&lt;/code&gt; after the first merge request event, as long as the source branch is still actively being developed.  Additionally, the job itself for this &lt;strong&gt;will run the source branch code, not the target branch code&lt;/strong&gt;.  For Gitlab Premium users, there is an additional criteria called a “merged_result_event”, which would run the target branch (&lt;code&gt;main&lt;/code&gt;) code after merging the source branch (&lt;code&gt;dev&lt;/code&gt;) into the target branch.&lt;/p&gt;
&lt;p&gt;Some of the (many) external links I used in this process:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://docs.gitlab.com/ee/ci/variables/predefined_variables.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Predefined&lt;/a&gt; CI/CD variables&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://gitlab.com/gitlab-org/gitlab/-/issues/214014&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Adding&lt;/a&gt; variables to the Gitlab CI/CD context&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://gitlab.com/gitlab-org/gitlab/-/issues/350582&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Setting&lt;/a&gt; up a ~/.netrc file with Gitlab credentials&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://stackoverflow.com/questions/72789599/gitlab-ci-cd-execute-script-file-that-exist-in-the-repository&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Executing&lt;/a&gt; a bash scripting within a Gitlab CI/CD pipeline&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://stackoverflow.com/questions/58939500/how-to-pass-gitlab-ci-file-variable-to-dockerfile-and-docker-container&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Passing&lt;/a&gt; variables to Docker image at build time&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://www.shellhacks.com/gitlab-ci-cd-build-docker-image-push-to-registry/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Building&lt;/a&gt; Docker image and pushing to registry&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://docs.gitlab.com/ee/user/packages/container_registry/authenticate_with_container_registry.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Authenticating&lt;/a&gt; container registries&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://docs.gitlab.com/ee/user/packages/pypi_repository/#authenticate-with-the-package-registry&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Setting&lt;/a&gt; up a ~/.pypirc files with Gitlab credentials&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>

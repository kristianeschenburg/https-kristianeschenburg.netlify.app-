<!DOCTYPE html><html lang="en-us" >

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.8.0">

  

  
  
  
  
  
    
    
    
  
  

  

  
  
  
    
  
  <meta name="description" content="I&rsquo;m going over Chapter 5 in Casella and Berger&rsquo;s (CB) &ldquo;Statistical Inference&rdquo;, specifically Section 5.5: Convergence Concepts, and wanted to document the topic of convergence in probability with some plots demonstrating the concept.
From CB, we have the definition of convergence in probability: a sequence of random variables $X_{1}, X_{2}, &hellip; X_{n}$ converges in probability to a random variable $X$, if for every $\epsilon &gt; 0$,">

  
  <link rel="alternate" hreflang="en-us" href="/post/convergence-in-probability/">

  


  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  
  
  <script src="/js/mathjax-config.js"></script>
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.0-1/css/all.min.css" integrity="sha256-4w9DunooKSr3MFXHXWyFER38WmPdm361bQS/2KUWZbU=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css" integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin="anonymous">
    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js" integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    

  

  
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  





<script async src="https://www.googletagmanager.com/gtag/js?id=UA-186337108-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url, target) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           if (target !== '_blank') {
             document.location = url;
           }
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target, event.target.getAttribute('target'));  
  }

  gtag('js', new Date());
  gtag('config', 'UA-186337108-1', {});

  
  document.addEventListener('click', onClickCallback, false);
</script>


  


  
  

  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/images/icon_hue3d34eb7f27f0837dcea880d4d221db4_377404_32x32_fill_lanczos_center_2.png">
  <link rel="apple-touch-icon" type="image/png" href="/images/icon_hue3d34eb7f27f0837dcea880d4d221db4_377404_192x192_fill_lanczos_center_2.png">

  <link rel="canonical" href="/post/convergence-in-probability/">

  
  
  
  
  
  
  
    
  
  
  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="A Rambling On">
  <meta property="og:url" content="/post/convergence-in-probability/">
  <meta property="og:title" content="Convergence In Probability | A Rambling On">
  <meta property="og:description" content="I&rsquo;m going over Chapter 5 in Casella and Berger&rsquo;s (CB) &ldquo;Statistical Inference&rdquo;, specifically Section 5.5: Convergence Concepts, and wanted to document the topic of convergence in probability with some plots demonstrating the concept.
From CB, we have the definition of convergence in probability: a sequence of random variables $X_{1}, X_{2}, &hellip; X_{n}$ converges in probability to a random variable $X$, if for every $\epsilon &gt; 0$,"><meta property="og:image" content="/img/Bayes.jpg">
  <meta property="twitter:image" content="/img/Bayes.jpg"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2018-11-28T13:12:32-07:00">
    
    <meta property="article:modified_time" content="2018-11-29T13:12:32-07:00">
  

  


    






  




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "/post/convergence-in-probability/"
  },
  "headline": "Convergence In Probability",
  
  "datePublished": "2018-11-28T13:12:32-07:00",
  "dateModified": "2018-11-29T13:12:32-07:00",
  
  "publisher": {
    "@type": "Organization",
    "name": "A Rambling On",
    "logo": {
      "@type": "ImageObject",
      "url": "/images/icon_hue3d34eb7f27f0837dcea880d4d221db4_377404_192x192_fill_lanczos_center_2.png"
    }
  },
  "description": "I\u0026rsquo;m going over Chapter 5 in Casella and Berger\u0026rsquo;s (CB) \u0026ldquo;Statistical Inference\u0026rdquo;, specifically Section 5.5: Convergence Concepts, and wanted to document the topic of convergence in probability with some plots demonstrating the concept.\nFrom CB, we have the definition of convergence in probability: a sequence of random variables $X_{1}, X_{2}, \u0026hellip; X_{n}$ converges in probability to a random variable $X$, if for every $\\epsilon \u0026gt; 0$,"
}
</script>

  

  


  


  





  <title>Convergence In Probability | A Rambling On</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  







<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">A Rambling On</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">A Rambling On</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#posts"><span>Posts</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Projects</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#publications"><span>Research</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/personal"><span>Personal</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/files/Resume.pdf"><span>Resume</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      <li class="nav-item dropdown theme-dropdown">
        <a href="#" class="nav-link js-theme-selector" data-toggle="dropdown" aria-haspopup="true">
          <i class="fas fa-palette" aria-hidden="true"></i>
        </a>
        <div class="dropdown-menu">
          <a href="#" class="dropdown-item js-set-theme-light">
            <span>Light</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-dark">
            <span>Dark</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-auto">
            <span>Automatic</span>
          </a>
        </div>
      </li>
      

      

    </ul>

  </div>
</nav>


  <article class="article">

  












  

  
  
  
<div class="article-container pt-3">
  <h1>Convergence In Probability</h1>

  

  
    


<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
          Last updated on
      
    
    Nov 29, 2018
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    4 min read
  </span>
  

  
  
  

  
  

</div>

    














  
</div>



  <div class="article-container">

    <div class="article-style">
      <p>I&rsquo;m going over <strong>Chapter 5</strong> in Casella and Berger&rsquo;s (CB) &ldquo;Statistical Inference&rdquo;, specifically <strong>Section 5.5: Convergence Concepts</strong>, and wanted to document the topic of 
<a href="https://en.wikipedia.org/wiki/Convergence_of_random_variables#Convergence_in_probability" target="_blank" rel="noopener">convergence in probability</a> with some plots demonstrating the concept.</p>
<p>From CB, we have the definition of <em>convergence in probability</em>: a sequence of random variables $X_{1}, X_{2}, &hellip; X_{n}$ converges in probability to a random variable $X$, if for every $\epsilon &gt; 0$,</p>
<p>$$\begin{align}
\lim_{n \to \infty} P(| X_{n} - X | \geq \epsilon) = 0 \\<br>
\end{align}$$</p>
<p>Intuitively, this means that, if we have some random variable $X_{k}$ and another random variable $X$, the absolute difference between $X_{k}$ and $X$ gets smaller and smaller as $k$ increases.  The probability that this difference exceeds some value, $\epsilon$, shrinks to zero as $k$ tends towards infinity.  Using *convergence in probability*, we can derive the 
<a href="https://en.wikipedia.org/wiki/Law_of_large_numbers#Weak_law" target="_blank" rel="noopener">Weak Law of Large Numbers</a> (WLLN):</p>
<p>$$\begin{align}
\lim_{n \to \infty} P(|\bar{X}_{n} - \mu | \geq \epsilon) = 0
\end{align}$$</p>
<p>which we can take to mean that the sample mean converges in probability to the population mean as the sample size goes to infinity.  If we have finite variance (that is $Var(X) &lt; \infty$), we can prove this using Chebyshev&rsquo;s Law</p>
<p>$$\begin{align}
&amp;= P(|\bar{X}_{n} - \mu | \geq \epsilon) \\<br>
&amp;= P((\bar{X}_{n} - \mu)^{2} \geq \epsilon^{2}) \leq \frac{E\Big[(\bar{X}_{n} - \mu)^{2}\Big]}{\epsilon^{2}} \\<br>
&amp;= P((\bar{X}_{n} - \mu)^{2} \geq \epsilon^{2}) \leq \frac{Var(\bar{X_{n}})}{\epsilon^{2}} \\<br>
&amp;= P((\bar{X}_{n} - \mu)^{2} \geq \epsilon^{2}) \leq \frac{\sigma^{2}}{n^{2}\epsilon^{2}}
\end{align}$$</p>
<p>where $\frac{\sigma^{2}}{n^{2} \epsilon^{2}} \rightarrow 0$ as $n \rightarrow \infty$.  Intuitively, this means, that the sample mean converges to the population mean &ndash; and the probability that their difference is larger than some value is bounded by the variance of the estimator.  Because we showed that the variance of the estimator (right hand side) shrinks to zero, we can show that the difference between the sample mean and population mean converges to zero.</p>
<p>We can also show a similar WLLN result for the sample variance using Chebyshev&rsquo;s Inequality, as:</p>
<p>$$\begin{align}
S_{n}^{2} = \frac{1}{n-1} \sum_{i=1}^{n} (X_{i} - \bar{X}_{n})^{2}
\end{align}$$</p>
<p>using the unbiased estimator, $S_{n}^{2}$, of $\sigma^{2}$ as follows:</p>
<p>$$\begin{align}
P(|S_{n}^{2} - \sigma^{2}| \geq \epsilon) \leq \frac{E\Big[(S_{n}^{2} - \sigma^{2})^{2}\Big]}{\epsilon^{2}} = \frac{Var(S_{n}^{2})}{\epsilon^{2}}
\end{align}$$</p>
<p>so all we need to do is show that $Var(S_{n}^{2}) \rightarrow 0$ as $n \rightarrow \infty$.</p>
<p>Let&rsquo;s have a look at some (simple) real-world examples.  We&rsquo;ll start by sampling from a $N(0,1)$ distribution, and compute the sample mean and variance using their unbiased estimators.</p>
<pre><code class="language-python"># Import numpy and scipy libraries
import numpy as np
from scipy.stats import norm

%matplotlib inline
import matplotlib.pyplot as plt

plt.rc('text', usetex=True)
</code></pre>
<pre><code class="language-python"># Generate set of samples sizes
samples = np.concatenate([np.arange(0, 105, 5), 
                          10*np.arange(10, 110, 10),
                         100*np.arange(10, 210, 10)])

# number of repeated samplings for each sample size
iterations = 500

# store sample mean and variance
means = np.zeros((iterations, len(samples)))
vsrs = np.zeros((iterations, len(samples)))

for i in np.arange(iterations):
    for j, s in enumerate(samples):
        
        # generate samples from N(0,1) distribution
        N = norm.rvs(loc=0, scale=1, size=s)
        mu = np.mean(N)
        
        # unbiased estimate of variance
        vr = ((N - mu)**2).sum()/(s-1)

        means[i, j] = mu
        vsrs[i, j] = vr
</code></pre>
<p>Let&rsquo;s have a look at the sample means and variances as a function of the sample size.  Empirically, we see that both the sample mean and variance estimates converge to their population parameters, 0 and 1.</p>
<p>




  
  











<figure id="figure-sample-mean-estimates-as-a-function-of-sample-size">


  <a data-fancybox="" href="/post/convergence-in-probability/WLLN_Mean_hub07fe3b7d9c1af829dbcf59ec07d859c_56103_2000x2000_fit_q90_lanczos.jpg" data-caption="Sample mean estimates as a function of sample size.">


  <img data-src="/post/convergence-in-probability/WLLN_Mean_hub07fe3b7d9c1af829dbcf59ec07d859c_56103_2000x2000_fit_q90_lanczos.jpg" class="lazyload" alt="" width="720" height="432">
</a>


  
  
  <figcaption>
    Sample mean estimates as a function of sample size.
  </figcaption>


</figure>






  
  











<figure id="figure-sample-variance-estimates-as-a-function-of-sample-size">


  <a data-fancybox="" href="/post/convergence-in-probability/WLLN_Variance_hu105b8336e2721323d12490083206465a_57888_2000x2000_fit_q90_lanczos.jpg" data-caption="Sample variance estimates as a function of sample size.">


  <img data-src="/post/convergence-in-probability/WLLN_Variance_hu105b8336e2721323d12490083206465a_57888_2000x2000_fit_q90_lanczos.jpg" class="lazyload" alt="" width="720" height="432">
</a>


  
  
  <figcaption>
    Sample variance estimates as a function of sample size.
  </figcaption>


</figure>
</p>
<p>Below is a simple method to compute the empirical probability that an estimate exceeds the epsilon threshold.</p>
<pre><code class="language-python">def ecdf(data, pparam, epsilon):
    
    &quot;&quot;&quot;
    Compute empirical probability P( |estimate - pop-param| &lt; epsilon).
    
    Parameters:
    - - - - -
    data: array, float
        array of samples
    pparam: float
        true population parameter
    epsilon: float
        threshold value
    &quot;&quot;&quot;
    
    compare = (np.abs(data - pparam) &lt; epsilon)
    prob = compare.mean(0)
    
    return prob
</code></pre>
<pre><code class="language-python"># test multiple epsilon thresholds
e = [0.9, 0.75, 0.5, 0.25, 0.1, 0.05, 0.01]

mean_probs = []
vrs_probs = []
# compute empirical probabilities at each threshold
for E in e:
    mean_probs.append(1 - ecdf(means, pparam=0, epsilon=E))
    vrs_probs.append(1-ecdf(vsrs, pparam=1, epsilon=E))
</code></pre>
<p>




  
  











<figure id="figure-empirical-probability-that-mean-estimate-exceeds-population-mean-by-epsilon">


  <a data-fancybox="" href="/post/convergence-in-probability/ECDF_Mean_hud239a6530d10b86e3a0a175784090642_43944_2000x2000_fit_q90_lanczos.jpg" data-caption="Empirical probability that mean estimate exceeds population mean by epsilon.">


  <img data-src="/post/convergence-in-probability/ECDF_Mean_hud239a6530d10b86e3a0a175784090642_43944_2000x2000_fit_q90_lanczos.jpg" class="lazyload" alt="" width="720" height="360">
</a>


  
  
  <figcaption>
    Empirical probability that mean estimate exceeds population mean by epsilon.
  </figcaption>


</figure>






  
  











<figure id="figure-empirical-probability-that-variance-estimate-exceeds-population-variance-by-epsilon">


  <a data-fancybox="" href="/post/convergence-in-probability/ECDF_Variance_hu4e0ed10e18641d62e69d3210311d0280_46360_2000x2000_fit_q90_lanczos.jpg" data-caption="Empirical probability that variance estimate exceeds population variance by epsilon.">


  <img data-src="/post/convergence-in-probability/ECDF_Variance_hu4e0ed10e18641d62e69d3210311d0280_46360_2000x2000_fit_q90_lanczos.jpg" class="lazyload" alt="" width="720" height="360">
</a>


  
  
  <figcaption>
    Empirical probability that variance estimate exceeds population variance by epsilon.
  </figcaption>


</figure>
</p>
<p>The above plots show that, as sample size increases, the mean estimator and variance estimator both converge to their true population parameters.  Likewise, examining the empirical probability plots, we can see that the probability that either estimate exceeds the epsilon thresholds shrinks to zero as the sample size increases.</p>
<p>If we wish to consider a stronger degree of convergence, we can consider <em>convergence almost surely</em>, which says the following:</p>
<p>$$\begin{align}
P(\lim_{n \to \infty} |X_{n} - X| \geq \epsilon) = 0 \<br>
\end{align}$$</p>
<p>which considers the entire joint distribution of estimates $( X_{1}, X_{2}&hellip;X_{n}, X)$, rather than all pairwise estimates $(X_{1},X), (X_{2},X)&hellip; (X_{n},X)$ &ndash; the entire set of estimates must converge to $X$ as the sample size approaches infinity.</p>

    </div>

    







<div class="share-box" aria-hidden="true">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=/post/convergence-in-probability/&amp;text=Convergence%20In%20Probability" target="_blank" rel="noopener" class="share-btn-twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=/post/convergence-in-probability/&amp;t=Convergence%20In%20Probability" target="_blank" rel="noopener" class="share-btn-facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=Convergence%20In%20Probability&amp;body=/post/convergence-in-probability/" target="_blank" rel="noopener" class="share-btn-email">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=/post/convergence-in-probability/&amp;title=Convergence%20In%20Probability" target="_blank" rel="noopener" class="share-btn-linkedin">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
  </ul>
</div>












  
  





  
    
    
    
      
    
    
    
    <div class="media author-card content-widget-hr">
      
        
        <img class="avatar mr-3 avatar-circle" src="/author/avatar_hu1d33f7c1c3956865c98823fdaf357458_38773_270x270_fill_q90_lanczos_center.jpg" alt="">
      

      <div class="media-body">
        <h5 class="card-title"><a href="/"></a></h5>
        <h6 class="card-subtitle">Data Scientist</h6>
        
        <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
    <li>
      <a href="mailto:keschenb@uw.edu" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://twitter.com/keschh" target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/kristianeschenburg" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.linkedin.com/in/kristianeschenburg/" target="_blank" rel="noopener">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
  
</ul>

      </div>
    </div>
  












  
  



  </div>
</article>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/languages/r.min.js"></script>
        
      

    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js" integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin="anonymous"></script>
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    <script>const isSiteThemeDark = false;</script>
    

    
    
    
    
    
    
    <script>
      const search_config = {"indexURI":"/index.json","minLength":1,"threshold":0.3};
      const i18n = {"no_results":"No results found","placeholder":"Search...","results":"results found"};
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.37431be2d92d7fb0160054761ab79602.js"></script>

    






  
  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" class="back-to-top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
